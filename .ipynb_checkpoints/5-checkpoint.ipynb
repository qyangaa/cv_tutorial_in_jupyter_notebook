{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More about deep networks\n",
    "## Understand neuron\n",
    "for one layer: each dimenaion of $x_i*\\omega$ is a neuron\n",
    "$$y = act(x*\\omega + b)$$\n",
    "## Information entropy\n",
    "$$-\\sum p_i\\log p_i$$\n",
    "Cross entropy loss:\n",
    "$$\n",
    "H(p, q)=-\\sum_{i} p_{i} \\log q_{i}=-y \\log \\hat{y}-(1-y) \\log (1-\\hat{y})\n",
    "$$\n",
    "If all samples are in the same class, then entropy = 0. If half one class, half the other one, entropy = 1. Then entropy shows purity of samples. \n",
    "## Preventing overfitting\n",
    "Regularize: add metrics of magnitude of weights in loss, e.g. $|\\omega|^2$\n",
    "\n",
    "L2 is used more commonly: For each loss, there are a surface of vectors on weight space that all have the same loss, L2 regularization makes sure that the model picks the smallest magnitude weight vector among these vectors.\n",
    "\n",
    "If use L1 loss, the model prefers sparse weight matrix (with many $\\omega_i=0$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree\n",
    "\n",
    "binary decision tree, key is to determine which criteria to put at each level. Use information gain to determin\n",
    "\n",
    "## ID3\n",
    "\n",
    "\n",
    "Conditional entropy $H(T|a)$ \n",
    "$$\n",
    "\\mathrm{H}(T \\mid a)=\\sum_{v \\in \\operatorname{vals}(a)} \\frac{\\left|S_{a}(v)\\right|}{|T|} \\cdot \\mathrm{H}\\left(S_{a}(v)\\right)\n",
    "$$\n",
    "Information gain, S is current classification, and the next step classfier classifies S into v subclasses, T is classifer strategy\n",
    "$$\n",
    "I G(T, a)=\\mathrm{H}(T)-\\mathrm{H}(T \\mid a)\n",
    "$$\n",
    "\n",
    "\n",
    "Only for classification\n",
    "\n",
    "## C4.5\n",
    "\n",
    "IG/spit entropy, the more subclasses we split the data into, the lower the value (splitting to much can result in overfitting.\n",
    "\n",
    "$$\n",
    "\\operatorname{split}(P, X)=-\\sum_{i=1}^{M} \\frac{\\left|D_{i}\\right|}{|D|} \\log _{2}\\left(\\frac{\\left|D_{i}\\right|}{|D|}\\right)\n",
    "$$\n",
    "\n",
    "## CART\n",
    "eg. CART (classification and regression tree)\n",
    "\n",
    "Classification with Gini Index:\n",
    "$$1-\\sum p_i^2$$\n",
    "\n",
    "Purity:\n",
    "$$p_l var(Y_l)+p_r var(Y_r)$$\n",
    "+ var = variance ($\\sum (y_i - \\bar{y})^2$)\n",
    "+ p = label (assigned as probability to be in a class, rather than IS or Not a class, for the case of regression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "\n",
    "No labels\n",
    "\n",
    "## K-means\n",
    "\n",
    "Issues:\n",
    "\n",
    "+ sensitive to initialization\n",
    "+ solved by K-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hct66 import *\n",
    "\n",
    "image_data,image_label = generate_data()\n",
    "#X1 = np.array([np.array(ida).reshape(36) for ida in image_data])\n",
    "X1 = np.array([np.array(get_feature(ida)).reshape(6) for ida in image_data])\n",
    "y1 = np.array(image_label)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import decision tree classifier model\n",
    "\n",
    "tree1 = DecisionTreeClassifier(criterion='entropy', # Initialize and fitclassifier\n",
    "max_depth=6, random_state=1)\n",
    "import pdb\n",
    "pdb.set_trace()\n",
    "tree1.fit(X1,y1)\n",
    "\n",
    "from pydotplus.graphviz import graph_from_dot_data\n",
    "from sklearn.tree import export_graphviz\n",
    "def display_tree(tree,class_names,feature_names,savename='tree.png'):\n",
    "    # Create dot data\n",
    "    dot_data = export_graphviz(\n",
    "    tree,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    #class_names=['Setosa','Versicolor','Virginica'],\n",
    "    #feature_names=['petallength', 'petal width'],\n",
    "    out_file=None\n",
    "    )\n",
    "    graph = graph_from_dot_data(dot_data) # Create graph from dot data\n",
    "    #graph.write_png('tree.png') # Write graphto PNG image\n",
    "    graph.write_png(savename) # Write graphto PNG image\n",
    "    \n",
    "class_names=['0','1','2','3','4','5','6','7','8','9']\n",
    "feature_names=[]\n",
    "for i in range(36):\n",
    "    feature_names.append(['f%s'%(i)])\n",
    "display_tree(tree1,class_names,feature_names,\"tree1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - facial keypoint detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "import math\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "import xgboost as xgb\n",
    "import cv2\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "\n",
    "class TrainSet(object):\n",
    "    def __init__(self):\n",
    "        self.imgDatas = []\n",
    "        self.gtShapes = []\n",
    "        self.bndBoxs  = []\n",
    "\n",
    "    def getBBoxByPts(self, pts):\n",
    "        maxV = np.max(pts, axis=0)\n",
    "        minV = np.min(pts, axis=0)\n",
    "\n",
    "        return (minV[0], minV[1],\n",
    "                maxV[0] - minV[0] + 1,\n",
    "                maxV[1] - minV[1] + 1)\n",
    "\n",
    "    def read(self, line, folder):\n",
    "        gtShape = []\n",
    "        # Load the ground truth of shape\n",
    "        line = re.split(r' ', line)\n",
    "        #rect = line[1:5]\n",
    "        x = line[5::2]\n",
    "        y = line[6::2]\n",
    "        for i in range(len(x)):\n",
    "            gtShape.append((x[i], y[i]))\n",
    "        gtShape = np.asarray(gtShape, dtype=np.float32)\n",
    "\n",
    "\n",
    "        # Load the image data\n",
    "        img_name = line[0]\n",
    "        img_path = folder + img_name\n",
    "        img = Image.open(img_path)\n",
    "        # gray image\n",
    "        img = img.convert('L')\n",
    "        img = np.asarray(img, dtype=np.uint8)\n",
    "        # print(img)\n",
    "\n",
    "        # Crop the image\n",
    "        bndBox = self.getBBoxByPts(gtShape)\n",
    "        return img, gtShape, bndBox\n",
    "\n",
    "    def cropRegion(self, bbox, scale, img):\n",
    "        height, width = img.shape\n",
    "        w = math.floor(scale * bbox[2])\n",
    "        h = math.floor(scale * bbox[3])\n",
    "        x = max(0, math.floor(bbox[0] - (w - bbox[2]) / 2))\n",
    "        y = max(0, math.floor(bbox[1] - (h - bbox[3]) / 2))\n",
    "        w = min(width - x, w)\n",
    "        h = min(height - y, h)\n",
    "\n",
    "        # If not use deepcopy, the subImg will hold the whole img's memory\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        subImg = copy.deepcopy(img[int(y):int(y + h), int(x):int(x + w)])\n",
    "        return (x, y, w, h), subImg\n",
    "\n",
    "    def add(self, img, gtShape, bndBox):\n",
    "        self.imgDatas.append(img)\n",
    "        self.gtShapes.append(gtShape)\n",
    "        self.bndBoxs.append(bndBox)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainSet = TrainSet()\n",
    "    folders = ['./facial-landmark-detection-master/data/I/', './facial-landmark-detection-master/data/II/']\n",
    "    folder = folders[0]\n",
    "    ann_path = folder + 'label1.txt'\n",
    "    lines = open(ann_path, 'r').readlines()\n",
    "\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        img, gtShape, bndBox = trainSet.read(line, folder)\n",
    "        scale = 2\n",
    "        cropB, img = trainSet.cropRegion(bndBox, scale, img)\n",
    "        gtShape = np.subtract(gtShape,\n",
    "                              (cropB[0], cropB[1]))\n",
    "        # print(gtShape[:, 0].flatten().shape)\n",
    "        labels.append(np.append(gtShape[:, 0].flatten(), gtShape[:, 1].flatten()))\n",
    "        # Get the bndBox.\n",
    "        bndBox = trainSet.getBBoxByPts(gtShape)\n",
    "\n",
    "        trainSet.add(img, gtShape, bndBox)\n",
    "    '''\n",
    "# show image and landmarks\n",
    "    for idx, line in enumerate(labels):\n",
    "        line = np.round(line).astype(np.int32)\n",
    "        x = line[0:21]\n",
    "        y = line[21:42]\n",
    "        showImg = cv2.cvtColor(trainSet.imgDatas[idx], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        for i in range(0, 21):\n",
    "            cv2.circle(showImg, (x[i], y[i]),\n",
    "                       3, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Landmark\", showImg)\n",
    "        key = cv2.waitKey(3000)\n",
    "        \n",
    "'''\n",
    "    # settings for LBP\n",
    "    radius = 2  # LBP算法中范围半径的取值\n",
    "    n_points = 8 * radius  # 领域像素点数\n",
    "    features = []\n",
    "    for idx, img in enumerate(trainSet.imgDatas):\n",
    "        width = 200\n",
    "        height = 200\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.resize((width, height), Image.NEAREST)\n",
    "\n",
    "        feature = local_binary_pattern(img, n_points, radius)\n",
    "        features.append(feature.flatten())\n",
    "\n",
    "    X = features\n",
    "    X = np.array(X, dtype=np.float)\n",
    "\n",
    "    Y = labels\n",
    "    Y = np.array(Y, dtype=np.float)\n",
    "    train_data_num = 10\n",
    "    X_train, X_test, y_train, y_test = X[0:train_data_num], \\\n",
    "                                       X[train_data_num:len(X)], \\\n",
    "                                       Y[0:train_data_num], \\\n",
    "                                       Y[train_data_num:len(X)]\n",
    "\n",
    "    #\n",
    "    # print('X_train shape:{}\\n X_test shape:{}\\n '\n",
    "    #       'y_train.shape: {}\\n y_test.shape:{}'.format(X_train.shape,\n",
    "    #                                                    X_test.shape,\n",
    "    #                                                    y_train.shape,\n",
    "    #                                                    y_test.shape))\n",
    "\n",
    "    # setup parameters for xgboost\n",
    "    xgbModel = xgb.XGBRegressor(objective='reg:squarederror', max_depth=10, learning_rate=0.3,\n",
    "                                n_estimators=50, silent=True)\n",
    "    # fitting\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    multioutputregressor = MultiOutputRegressor(xgbModel).fit(X_train,y_train)\n",
    "    #                                                          verbose=True)\n",
    "    pred = multioutputregressor.predict(X)\n",
    "\n",
    "    for idx, line in enumerate(pred):\n",
    "        line = np.round(line).astype(np.int32)\n",
    "        x = line[0:21]\n",
    "        y = line[21:42]\n",
    "        showImg = cv2.cvtColor(trainSet.imgDatas[idx], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        for i in range(0, 21):\n",
    "            cv2.circle(showImg, (x[i], y[i]),\n",
    "                       3, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Landmark\", showImg)\n",
    "        key = cv2.waitKey(3000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "K-means++ to segregate HCT66 into 3 sets.\n",
    "\n",
    "Discuss difference between K-means and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
