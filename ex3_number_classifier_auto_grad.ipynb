{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "1. Generate numbers\n",
    "2. Extract features\n",
    "3. Create classification model with linear classifier\n",
    "4. Train with gradient descent (using auto_grad from pytorch)\n",
    "\n",
    "## Generate numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_data():\n",
    "    # generage number matrix\n",
    "    image_data=[]\n",
    "    num_0 = torch.tensor(\n",
    "    [[0,0,1,1,0,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,0,1,1,0,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_0)\n",
    "    num_1 = torch.tensor(\n",
    "    [[0,0,0,1,0,0],\n",
    "    [0,0,1,1,0,0],\n",
    "    [0,0,0,1,0,0],\n",
    "    [0,0,0,1,0,0],\n",
    "    [0,0,1,1,1,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_1)\n",
    "    num_2 = torch.tensor(\n",
    "    [[0,0,1,1,0,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,0,0,1,0,0],\n",
    "    [0,0,1,0,0,0],\n",
    "    [0,1,1,1,1,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_2)\n",
    "    num_3 = torch.tensor(\n",
    "    [[0,0,1,1,0,0],\n",
    "    [0,0,0,0,1,0],\n",
    "    [0,0,1,1,0,0],\n",
    "    [0,0,0,0,1,0],\n",
    "    [0,0,1,1,0,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_3)\n",
    "    num_4 = torch.tensor(\n",
    "    [\n",
    "    [0,0,0,0,1,0],\n",
    "    [0,0,0,1,1,0],\n",
    "    [0,0,1,0,1,0],\n",
    "    [0,1,1,1,1,1],\n",
    "    [0,0,0,0,1,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_4)\n",
    "    num_5 = torch.tensor(\n",
    "    [\n",
    "    [0,1,1,1,0,0],\n",
    "    [0,1,0,0,0,0],\n",
    "    [0,1,1,1,0,0],\n",
    "    [0,0,0,0,1,0],\n",
    "    [0,1,1,1,0,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_5)\n",
    "    num_6 = torch.tensor(\n",
    "    [[0,0,1,1,0,0],\n",
    "    [0,1,0,0,0,0],\n",
    "    [0,1,1,1,0,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,0,1,1,0,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_6)\n",
    "    num_7 = torch.tensor(\n",
    "    [\n",
    "    [0,1,1,1,1,0],\n",
    "    [0,0,0,0,1,0],\n",
    "    [0,0,0,1,0,0],\n",
    "    [0,0,0,1,0,0],\n",
    "    [0,0,0,1,0,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_7)\n",
    "    num_8 = torch.tensor(\n",
    "    [[0,0,1,1,0,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,0,1,1,0,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,0,1,1,0,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_8)\n",
    "    num_9 = torch.tensor(\n",
    "    [[0,0,1,1,1,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,0,1,1,1,0],\n",
    "    [0,1,0,0,1,0],\n",
    "    [0,0,0,0,1,0],\n",
    "    [0,0,0,0,0,0]])\n",
    "    image_data.append(num_9)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction function\n",
    "HOG\n",
    "\n",
    "LBP\n",
    "\n",
    "SUFR\n",
    "\n",
    "SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 4, 4, 5, 0])\n"
     ]
    }
   ],
   "source": [
    "def hog(image):\n",
    "    image = image.numpy()\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    h, w = image.shape[:2]\n",
    "    rate = 64 / w\n",
    "    image = cv2.resize(image, (64, np.int(rate*h)))\n",
    "    bg = np.zeros((128, 64), dtype=np.uint8)\n",
    "    print(bg.shape,image.shape)\n",
    "    bg[:,:] = 127\n",
    "    h, w = image.shape\n",
    "    dy = (128 - h) // 2\n",
    "    bg[dy:h+dy,:] = image\n",
    "    descriptors = hog.compute(bg, winStride=(8, 8), padding=(0, 0))\n",
    "    return descriptors\n",
    "\n",
    "def LBP(gray_image, window=3):\n",
    "    lbp = np.zeros_like(gray_image)\n",
    "    h,w = gray_image.shape\n",
    "    p_center = window//2\n",
    "    for ph in range(0,h-window):\n",
    "        for pw in range(0,w-window):\n",
    "            img = gray_image[ph:ph+window, pw:pw+window]\n",
    "            center = img[p_center,p_center]\n",
    "            binary = (img>=center)*1.0\n",
    "            binary_vector = binary.flatten()\n",
    "            #remove center point\n",
    "            binary_vector = np.delete(binary_vector,4)\n",
    "            res = 0\n",
    "            for i in range(len(binary_vector)):\n",
    "                if binary_vector[i]==1:\n",
    "                    res+= 2**i\n",
    "            lbp[ph+p_center,pw+p_center] = res\n",
    "    return lbp\n",
    "\n",
    "def get_feature(x):\n",
    "    \"\"\"feature extraction\"\"\"\n",
    "    feature = torch.sum(x,0)+torch.sum(x,1)\n",
    "    feature = feature\n",
    "    return feature\n",
    "\n",
    "image_data = generate_data()\n",
    "print(get_feature(image_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "class model:\n",
    "    def __init__(self, sample_input, lr=0.001,out_channels=10,feature = get_feature):\n",
    "        \"\"\"\n",
    "        a binary classifier to classify target digit\n",
    "        sample_input:used to automatically set shape of weight matrices\n",
    "        lr: learning rate\n",
    "        \"\"\"\n",
    "        self.channels=out_channels\n",
    "        self.w = torch.tensor(np.random.rand(*([self.channels]+list(sample_input.shape))))\n",
    "        self.lr = lr\n",
    "        \n",
    "        #built-in functions for forward and backward calculations\n",
    "        self.feature = feature\n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        #print(self.w.shape,x.view(-1,1).shape)\n",
    "        x = torch.mm(self.w,x.view(-1,1).double()) #matrix multiplication\n",
    "        out = x/sum(x) #normalize to become probability logits\n",
    "        #built-in data storage for backward calculation\n",
    "        self.y_hat = out.flatten()\n",
    "        return out\n",
    "    def loss(self,y,LossFunc = None):\n",
    "        if isinstance(y,int): #if input is an integer\n",
    "            y=[y]\n",
    "        y = np.array(y)\n",
    "        if len(y.shape)==1: #requires one-hot encoding of y\n",
    "            one_hot = np.zeros((y.size, self.channels))\n",
    "            one_hot[np.arange(y.size),y]=1\n",
    "            y = one_hot.flatten()\n",
    "        self.y = torch.tensor(y)\n",
    "        return torch.mean((self.y_hat-self.y)**2)\n",
    "    def update(self):\n",
    "        gradient = 2*(self.y_hat-self.y).view(-1,1)*self.x.view(1,-1)\n",
    "        self.w -= self.lr*gradient\n",
    "        return\n",
    "    def predict(self,x):\n",
    "        logits = self.forward(x)\n",
    "        return torch.argmax(logits)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = model(get_feature(image_data[0]))\n",
    "m.forward(get_feature(image_data[0]))\n",
    "loss = m.loss(0)\n",
    "m.update()\n",
    "m.predict(get_feature(image_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = np.array([9])\n",
    "b = np.zeros((a.size, 9+1))\n",
    "b[np.arange(a.size),a] = 1\n",
    "torch.argmax(torch.tensor(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = get_feature(image_data[0])\n",
    "w = torch.tensor(np.random.rand(*([8]+list(a.shape))))\n",
    "print(a.shape,w.shape)\n",
    "out = torch.mm(w,a.view(-1,1).double())\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(feature,epochs,mode='train',print_every = 100, model=model,**kwargs):\n",
    "    labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "    m = model(feature(image_data[0]),0.1,out_channels=len(labels))\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for i,x in enumerate(image_data):\n",
    "            v = feature(x)\n",
    "            y = labels[i]\n",
    "            o = m.forward(v)\n",
    "            if mode=='debug':\n",
    "                return m\n",
    "            cur_loss = m.loss(y)\n",
    "            loss+=cur_loss\n",
    "            m.update()\n",
    "            pred = m.predict(v)\n",
    "\n",
    "\n",
    "        if epoch%print_every==0:\n",
    "            print(\"epoch: {}, loss: {}\".format(epoch,loss))\n",
    "    for i,x in enumerate(image_data):\n",
    "        v = feature(x)\n",
    "        print('prediction of number {} is :{}'.format(i,m.predict(v)))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.034706817362325\n",
      "epoch: 100, loss: 0.5874769553484933\n",
      "epoch: 200, loss: 0.5636475721187735\n",
      "epoch: 300, loss: 0.5475244920066803\n",
      "epoch: 400, loss: 0.5347499267654419\n",
      "epoch: 500, loss: 0.5246355669785214\n",
      "epoch: 600, loss: 0.5166412079336254\n",
      "epoch: 700, loss: 0.5103285784581413\n",
      "epoch: 800, loss: 0.5053480904946634\n",
      "epoch: 900, loss: 0.5014221551998018\n",
      "prediction of number 0 is :0\n",
      "prediction of number 1 is :1\n",
      "prediction of number 2 is :2\n",
      "prediction of number 3 is :3\n",
      "prediction of number 4 is :4\n",
      "prediction of number 5 is :6\n",
      "prediction of number 6 is :6\n",
      "prediction of number 7 is :7\n",
      "prediction of number 8 is :6\n",
      "prediction of number 9 is :9\n"
     ]
    }
   ],
   "source": [
    "#this feature function does not distinguish between 6 and 8\n",
    "feature = get_feature\n",
    "epochs=1000\n",
    "train_and_test(feature,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.9386055958690203\n",
      "epoch: 100, loss: 0.17530046658964013\n",
      "epoch: 200, loss: 0.09131533697425613\n",
      "epoch: 300, loss: 0.05952200558154673\n",
      "epoch: 400, loss: 0.04165872882866667\n",
      "epoch: 500, loss: 0.03012948033006923\n",
      "epoch: 600, loss: 0.02221338059343832\n",
      "epoch: 700, loss: 0.016577221351129084\n",
      "epoch: 800, loss: 0.01246788258669094\n",
      "epoch: 900, loss: 0.00942404622307222\n",
      "prediction of number 0 is :0\n",
      "prediction of number 1 is :1\n",
      "prediction of number 2 is :2\n",
      "prediction of number 3 is :3\n",
      "prediction of number 4 is :4\n",
      "prediction of number 5 is :5\n",
      "prediction of number 6 is :6\n",
      "prediction of number 7 is :7\n",
      "prediction of number 8 is :8\n",
      "prediction of number 9 is :9\n"
     ]
    }
   ],
   "source": [
    "#use flattened x as output directly, enforce overfitting in real case\n",
    "feature = lambda x: x.flatten()\n",
    "epochs=1000\n",
    "train_and_test(feature,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1])\n",
      "tensor([8, 6, 1])\n",
      "tensor([ 4, 10,  1])\n",
      "tensor([4, 0, 2])\n",
      "tensor([14,  6,  2])\n",
      "tensor([10,  4,  2])\n",
      "tensor([4, 2, 2])\n",
      "tensor([ 8, 10,  1])\n",
      "tensor([0, 0, 2])\n",
      "tensor([6, 4, 2])\n",
      "epoch: 0, loss: 1.0746936978336885\n",
      "epoch: 100, loss: 0.9868466251490494\n",
      "epoch: 200, loss: 0.9868481050656508\n",
      "epoch: 300, loss: 0.986848105076528\n",
      "epoch: 400, loss: 0.986848105076528\n",
      "epoch: 500, loss: 0.986848105076528\n",
      "epoch: 600, loss: 0.986848105076528\n",
      "epoch: 700, loss: 0.986848105076528\n",
      "epoch: 800, loss: 0.986848105076528\n",
      "epoch: 900, loss: 0.986848105076528\n",
      "prediction of number 0 is :8\n",
      "prediction of number 1 is :7\n",
      "prediction of number 2 is :2\n",
      "prediction of number 3 is :5\n",
      "prediction of number 4 is :4\n",
      "prediction of number 5 is :5\n",
      "prediction of number 6 is :9\n",
      "prediction of number 7 is :7\n",
      "prediction of number 8 is :8\n",
      "prediction of number 9 is :7\n"
     ]
    }
   ],
   "source": [
    "#does not properly train\n",
    "\n",
    "def get_feature2(x):\n",
    "    \"\"\"feature extraction from ex2\"\"\"\n",
    "    img = x[:5,]\n",
    "    lr = torch.flip(img,[1])\n",
    "    lr_sym = img - lr\n",
    "    lr_sum = sum(sum(abs(lr_sym)))\n",
    "    ud = torch.flip(img,[0])\n",
    "    ud_sym = img-ud\n",
    "    ud_sum = sum(sum(abs(ud_sym)))\n",
    "    mid_sum = sum(img[3,:])\n",
    "    #added center element to distinguish between 0 and 8\n",
    "    center = img[2,2]+1\n",
    "    #convert tensor to float for more digit precision\n",
    "    #convert back to int to prevent additional floating point calculation\n",
    "    out =torch.cat((lr_sum.view(-1),ud_sum.view(-1),center.view(-1)))\n",
    "    #print(out)\n",
    "    return out\n",
    "\n",
    "for image in image_data:\n",
    "    print(get_feature2(image))\n",
    "feature = get_feature2\n",
    "epochs=1000\n",
    "m = train_and_test(feature,epochs,lr = 0.001,mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.3000, 0.2740, 0.3588, 0.7628, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.2500, 0.8000, 0.4878, 0.0000])\n",
      "tensor([0.0000, 0.2000, 0.3659, 0.5390, 0.6442, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.3750, 0.5581, 0.6819, 0.0000])\n",
      "tensor([0.0000, 0.0909, 0.1982, 0.2413, 0.7657, 0.4355])\n",
      "tensor([0.0000, 0.3636, 0.4074, 0.6288, 0.4167, 0.0000])\n",
      "tensor([0.0000, 0.3000, 0.4110, 0.6368, 0.4259, 0.0000])\n",
      "tensor([0.0000, 0.1250, 0.1404, 0.6384, 0.6888, 0.0000])\n",
      "tensor([0.0000, 0.2000, 0.3659, 0.5390, 0.6442, 0.0000])\n",
      "tensor([0.0000, 0.1818, 0.2178, 0.2703, 0.8818, 0.0000])\n",
      "epoch: 0, loss: 0.9311403056610096\n",
      "epoch: 100, loss: 0.6902613454432747\n",
      "epoch: 200, loss: 0.6176524563579978\n",
      "epoch: 300, loss: 0.5813448952287088\n",
      "epoch: 400, loss: 0.5601661088343235\n",
      "epoch: 500, loss: 0.5467450786116319\n",
      "epoch: 600, loss: 0.5377250915680553\n",
      "epoch: 700, loss: 0.5314011745582023\n",
      "epoch: 800, loss: 0.5268336226879181\n",
      "epoch: 900, loss: 0.5234657504788891\n",
      "epoch: 1000, loss: 0.5209466959750263\n",
      "epoch: 1100, loss: 0.5190438092924353\n",
      "epoch: 1200, loss: 0.5175965222720889\n",
      "epoch: 1300, loss: 0.5164905583939031\n",
      "epoch: 1400, loss: 0.5156426897015804\n",
      "epoch: 1500, loss: 0.5149912610861246\n",
      "epoch: 1600, loss: 0.5144900300496554\n",
      "epoch: 1700, loss: 0.5141040041332462\n",
      "epoch: 1800, loss: 0.513806535930804\n",
      "epoch: 1900, loss: 0.5135772421991323\n",
      "epoch: 2000, loss: 0.5134004825636257\n",
      "epoch: 2100, loss: 0.5132642299346516\n",
      "epoch: 2200, loss: 0.513159222038489\n",
      "epoch: 2300, loss: 0.5130783187104725\n",
      "epoch: 2400, loss: 0.5130160120901648\n",
      "epoch: 2500, loss: 0.5129680517289407\n",
      "epoch: 2600, loss: 0.5129311567767212\n",
      "epoch: 2700, loss: 0.5129027945511322\n",
      "epoch: 2800, loss: 0.5128810099272029\n",
      "epoch: 2900, loss: 0.5128642937508574\n",
      "epoch: 3000, loss: 0.5128514812808719\n",
      "epoch: 3100, loss: 0.5128416737712718\n",
      "epoch: 3200, loss: 0.5128341779041137\n",
      "epoch: 3300, loss: 0.5128284590014023\n",
      "epoch: 3400, loss: 0.5128241048783393\n",
      "epoch: 3500, loss: 0.51282079791712\n",
      "epoch: 3600, loss: 0.5128182934923846\n",
      "epoch: 3700, loss: 0.5128164033048279\n",
      "epoch: 3800, loss: 0.5128149825076996\n",
      "epoch: 3900, loss: 0.5128139197643545\n",
      "epoch: 4000, loss: 0.512813129570767\n",
      "epoch: 4100, loss: 0.512812546328185\n",
      "epoch: 4200, loss: 0.5128121197680053\n",
      "epoch: 4300, loss: 0.5128118114213073\n",
      "epoch: 4400, loss: 0.5128115918953321\n",
      "epoch: 4500, loss: 0.5128114387731949\n",
      "epoch: 4600, loss: 0.5128113349948479\n",
      "epoch: 4700, loss: 0.5128112676095926\n",
      "epoch: 4800, loss: 0.5128112268153677\n",
      "epoch: 4900, loss: 0.5128112052193308\n",
      "epoch: 5000, loss: 0.512811197269146\n",
      "epoch: 5100, loss: 0.5128111988159121\n",
      "epoch: 5200, loss: 0.5128112067785583\n",
      "epoch: 5300, loss: 0.5128112188864257\n",
      "epoch: 5400, loss: 0.5128112334820507\n",
      "epoch: 5500, loss: 0.5128112493702843\n",
      "epoch: 5600, loss: 0.5128112657030472\n",
      "epoch: 5700, loss: 0.5128112818914679\n",
      "epoch: 5800, loss: 0.5128112975390455\n",
      "epoch: 5900, loss: 0.5128113123909404\n",
      "epoch: 6000, loss: 0.5128113262956132\n",
      "epoch: 6100, loss: 0.5128113391759168\n",
      "epoch: 6200, loss: 0.5128113510074014\n",
      "epoch: 6300, loss: 0.5128113618021218\n",
      "epoch: 6400, loss: 0.5128113715966267\n",
      "epoch: 6500, loss: 0.512811380443122\n",
      "epoch: 6600, loss: 0.5128113884030333\n",
      "epoch: 6700, loss: 0.5128113955423759\n",
      "epoch: 6800, loss: 0.5128114019284808\n",
      "epoch: 6900, loss: 0.5128114076277329\n",
      "epoch: 7000, loss: 0.5128114127040583\n",
      "epoch: 7100, loss: 0.5128114172179623\n",
      "epoch: 7200, loss: 0.5128114212259701\n",
      "epoch: 7300, loss: 0.5128114247803544\n",
      "epoch: 7400, loss: 0.5128114279290664\n",
      "epoch: 7500, loss: 0.5128114307158077\n",
      "epoch: 7600, loss: 0.5128114331801947\n",
      "epoch: 7700, loss: 0.5128114353579827\n",
      "epoch: 7800, loss: 0.5128114372813231\n",
      "epoch: 7900, loss: 0.512811438979038\n",
      "epoch: 8000, loss: 0.5128114404768969\n",
      "epoch: 8100, loss: 0.5128114417978888\n",
      "epoch: 8200, loss: 0.5128114429624835\n",
      "epoch: 8300, loss: 0.5128114439888778\n",
      "epoch: 8400, loss: 0.5128114448932248\n",
      "epoch: 8500, loss: 0.5128114456898467\n",
      "epoch: 8600, loss: 0.5128114463914292\n",
      "epoch: 8700, loss: 0.5128114470091969\n",
      "epoch: 8800, loss: 0.5128114475530753\n",
      "epoch: 8900, loss: 0.5128114480318346\n",
      "epoch: 9000, loss: 0.5128114484532194\n",
      "epoch: 9100, loss: 0.5128114488240649\n",
      "epoch: 9200, loss: 0.5128114491504016\n",
      "epoch: 9300, loss: 0.5128114494375472\n",
      "epoch: 9400, loss: 0.5128114496901899\n",
      "epoch: 9500, loss: 0.5128114499124607\n",
      "epoch: 9600, loss: 0.5128114501080002\n",
      "epoch: 9700, loss: 0.5128114502800145\n",
      "epoch: 9800, loss: 0.5128114504313273\n",
      "epoch: 9900, loss: 0.5128114505644246\n",
      "prediction of number 0 is :0\n",
      "prediction of number 1 is :1\n",
      "prediction of number 2 is :3\n",
      "prediction of number 3 is :3\n",
      "prediction of number 4 is :4\n",
      "prediction of number 5 is :5\n",
      "prediction of number 6 is :5\n",
      "prediction of number 7 is :7\n",
      "prediction of number 8 is :3\n",
      "prediction of number 9 is :9\n"
     ]
    }
   ],
   "source": [
    "#This is not better than first method\n",
    "\n",
    "def get_feature3(x):\n",
    "    feature=[0,0,0,0]\n",
    "    # 下面添加提取图像x的特征feature的代码\n",
    "    def get_shadow(x,dim):\n",
    "        feature  =torch.sum(x,dim)\n",
    "        feature = feature.float()\n",
    "        # 归一化\n",
    "        for i in range(0,feature.shape[0]):\n",
    "            feature[i]=feature[i]/sum(feature)\n",
    "\n",
    "        feature = feature.view(1,6)\n",
    "        return feature\n",
    "    feature  = get_shadow(x,0)\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    #print(feature)\n",
    "    return feature.flatten()\n",
    "\n",
    "for image in image_data:\n",
    "    print(get_feature3(image))\n",
    "    \n",
    "feature = get_feature3\n",
    "epochs=10000\n",
    "m = train_and_test(feature,epochs,lr = 0.1,mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=torch.float64)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with auto_grad\n",
    "\n",
    "1. requires_grad: to retain gradient\n",
    "    1. To check status of a variable: a.requires_grad\n",
    "2. Cannot use backward with vector, only scalar. Because loss function is a scalar. Easy to adapt for vector\n",
    "3. Cannot change graph of grad, two ways to update weights:\n",
    "    1. with torch.nn.no_grad():\n",
    "    2. update weights.data directly\n",
    "4. Need to zero gradient after every update: \n",
    "    1. weights.grad.data.zero_()\n",
    "    2. weights.grad.data = zeros(....)\n",
    "5. Cannot backward() for more than once: RuntimeError. Need to use retain_grad (retain the calculated values) in order to backward multiple times. \n",
    "6. Leaf node:\n",
    "    1. Used to save memory\n",
    "    2. Leaf nodes have 'None\" grad_fn\n",
    "    3. None-leaf nodes have grad_fn that's not 'None'\n",
    "    4. Determine if a variable is leaf node: a.is_leaf\n",
    "    5. If we want to retain gradients of intermediate variable, use retain_grad. Memory will be release by default if not set this way.\n",
    "    6. If we only need to output grad information of intermediate variables but not saving them, use tensor.register_hook\n",
    "        1. e.g. loss2.register_hook(lambda grad:print(\"loss grad:\",grad))\n",
    "        2. memory is released after printing\n",
    "7. In-place operation\n",
    "    1. pytorch use b._version to detect. Every time a tensor has inplace operation, version increment by 1. \n",
    "    2. If not inplace operation, varible id increments. (check by id(a))\n",
    "    3. in-place operation not allowed for leaf variables with requires_grad=True [RuntimeError: leaf variable has been moved into the graph interior]\n",
    "    4. ways to change data of leaf variables:\n",
    "        1. a.data.fill_ (or other built-in operations)\n",
    "        2. with torch.no_grad():\n",
    "    5. a.data shares memory with a, but with requires_grad = False\n",
    "\n",
    "### Examples with auto_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], requires_grad=True)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,10)\n",
    "w = torch.ones(10,1,requires_grad=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.7640]], grad_fn=<MmBackward>)\n",
      "tensor([[189.4480]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x.mm(w)\n",
    "print(y)\n",
    "loss = (y-8)*(y-8)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradience calculation\n",
    "loss.backward()\n",
    "g = w.grad\n",
    "w = w +g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with auto_grad\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class model_auto_grad:\n",
    "    def __init__(self, sample_input, lr=0.001,out_channels=10,feature = get_feature):\n",
    "        \"\"\"\n",
    "        a binary classifier to classify target digit\n",
    "        sample_input:used to automatically set shape of weight matrices\n",
    "        lr: learning rate\n",
    "        target: the target digit to classify as IS TARGET or NOT TARGET\n",
    "        \"\"\"\n",
    "        self.channels=out_channels\n",
    "        self.w = torch.tensor(np.random.rand(*([self.channels]+list(sample_input.shape))),requires_grad=True)\n",
    "        #self.b = torch.tensor(np.random.rand(self.channels,1),requires_grad=True)\n",
    "        self.lr = lr\n",
    "        #built-in functions for forward and backward calculations\n",
    "        self.feature = feature\n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        #print(self.w.shape,x.view(-1,1).shape)\n",
    "        x = torch.mm(self.w,x.view(-1,1).double()) #matrix multiplication\n",
    "        #x = x+self.b\n",
    "        out = x/sum(x) #normalize to become probability logits\n",
    "        #built-in data storage for backward calculation\n",
    "        self.y_hat = out.flatten()\n",
    "        return out\n",
    "    def L2(self,y):\n",
    "        return torch.mean((self.y_hat-self.y)**2)\n",
    "    def CrossEntropy(self, y):\n",
    "        loss = torch.tensor(0.0,requires_grad=True)\n",
    "        i=0\n",
    "        yHat = self.y_hat\n",
    "        #print(yHat)\n",
    "        for pred in yHat:\n",
    "            if y[i] == 1:\n",
    "                 loss = loss - torch.log(pred)\n",
    "            else:\n",
    "                loss = loss -torch.log(1 - pred)\n",
    "            i+=1\n",
    "        return loss/i\n",
    "    def loss(self,y,LossFunc = CrossEntropy):\n",
    "        if isinstance(y,int): #if input is an integer\n",
    "            y=[y]\n",
    "        y = np.array(y)\n",
    "        if len(y.shape)==1: #requires one-hot encoding of y\n",
    "            one_hot = np.zeros((y.size, self.channels))\n",
    "            one_hot[np.arange(y.size),y]=1\n",
    "            y = one_hot.flatten()\n",
    "        self.y = torch.tensor(y)\n",
    "        #use cross entropy here\n",
    "        #CrossEntropy.requres_grad = True\n",
    "        self.loss_val = LossFunc(self,y)\n",
    "        #self.loss_val = torch.mean((self.y_hat-self.y)**2)\n",
    "        self.loss_val.backward()\n",
    "        return self.loss_val\n",
    "        \n",
    "    def update(self):\n",
    "        #print(self.w.grad)\n",
    "        g_w = self.w.grad.data\n",
    "        #g_b = self.b.grad.data\n",
    "        self.w.data -= self.lr*g_w\n",
    "        #self.b.data -= self.lr*g_b\n",
    "        self.w.grad.data.zero_()\n",
    "        #self.b.grad.data.zero_()\n",
    "        return\n",
    "    def predict(self,x):\n",
    "        logits = self.forward(x)\n",
    "        return torch.argmax(logits)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.892553625233369\n",
      "epoch: 1000, loss: 0.8091974416705341\n",
      "epoch: 2000, loss: 0.342985607084156\n",
      "epoch: 3000, loss: 0.047219599635461185\n",
      "epoch: 4000, loss: 0.004394038533564421\n",
      "epoch: 5000, loss: 0.0004145834866336078\n",
      "epoch: 6000, loss: 4.2994079831998436e-05\n",
      "epoch: 7000, loss: 4.6875652503879375e-06\n",
      "epoch: 8000, loss: 5.279212613092977e-07\n",
      "epoch: 9000, loss: 6.087098345455412e-08\n",
      "prediction of number 0 is :0\n",
      "prediction of number 1 is :1\n",
      "prediction of number 2 is :2\n",
      "prediction of number 3 is :3\n",
      "prediction of number 4 is :4\n",
      "prediction of number 5 is :5\n",
      "prediction of number 6 is :6\n",
      "prediction of number 7 is :7\n",
      "prediction of number 8 is :8\n",
      "prediction of number 9 is :9\n"
     ]
    }
   ],
   "source": [
    "#use L2 loss\n",
    "feature = lambda x: x.flatten()\n",
    "epochs=10000\n",
    "m = train_and_test(feature,epochs,model=model_auto_grad,lr=1,print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = lambda x: x.flatten()\n",
    "epochs=1000\n",
    "m = train_and_test(feature,epochs,model=model_auto_grad,lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.9177928427830887\n",
      "epoch: 1000, loss: 0.8818461794976101\n",
      "epoch: 2000, loss: 0.7744264048204932\n",
      "epoch: 3000, loss: 0.46891190756080103\n",
      "epoch: 4000, loss: 0.47503682193944263\n",
      "epoch: 5000, loss: 0.41032769604410213\n",
      "epoch: 6000, loss: 0.41187691804068166\n",
      "epoch: 7000, loss: 0.40818076416436433\n",
      "epoch: 8000, loss: 0.4079299012959047\n",
      "epoch: 9000, loss: 0.40757624078808863\n",
      "prediction of number 0 is :0\n",
      "prediction of number 1 is :1\n",
      "prediction of number 2 is :2\n",
      "prediction of number 3 is :3\n",
      "prediction of number 4 is :4\n",
      "prediction of number 5 is :6\n",
      "prediction of number 6 is :6\n",
      "prediction of number 7 is :7\n",
      "prediction of number 8 is :6\n",
      "prediction of number 9 is :2\n"
     ]
    }
   ],
   "source": [
    "#use L2 loss\n",
    "feature = get_feature\n",
    "epochs=10000\n",
    "m = train_and_test(feature,epochs,model=model_auto_grad,lr=0.01,print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 3.272478737144247\n",
      "epoch: 100, loss: 3.098681159196158\n",
      "epoch: 200, loss: 2.949812361865163\n",
      "epoch: 300, loss: 2.7955675820042014\n",
      "epoch: 400, loss: 2.5998120074725586\n",
      "prediction of number 0 is :0\n",
      "prediction of number 1 is :1\n",
      "prediction of number 2 is :2\n",
      "prediction of number 3 is :3\n",
      "prediction of number 4 is :4\n",
      "prediction of number 5 is :5\n",
      "prediction of number 6 is :6\n",
      "prediction of number 7 is :7\n",
      "prediction of number 8 is :8\n",
      "prediction of number 9 is :9\n"
     ]
    }
   ],
   "source": [
    "#use Cross Entropy loss\n",
    "feature = lambda x: x.flatten()\n",
    "epochs=500\n",
    "m = train_and_test(feature,epochs,model=model_auto_grad,lr=1,print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 3.3816390151883344\n",
      "epoch: 100, loss: 3.2357709068355027\n",
      "epoch: 200, loss: 3.17739580136705\n",
      "epoch: 300, loss: 3.121404563687707\n",
      "epoch: 400, loss: 3.0513159660598648\n",
      "prediction of number 0 is :0\n",
      "prediction of number 1 is :1\n",
      "prediction of number 2 is :9\n",
      "prediction of number 3 is :3\n",
      "prediction of number 4 is :4\n",
      "prediction of number 5 is :5\n",
      "prediction of number 6 is :6\n",
      "prediction of number 7 is :7\n",
      "prediction of number 8 is :8\n",
      "prediction of number 9 is :2\n"
     ]
    }
   ],
   "source": [
    "#use Cross Entropy Loss\n",
    "feature = get_feature\n",
    "epochs=500\n",
    "m = train_and_test(feature,epochs,model=model_auto_grad,lr=0.01,print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(x):\n",
    "    feature=[0,0,0,0]\n",
    "    def get_shadow(x,dim):\n",
    "        feature  =torch.sum(x,dim)\n",
    "        feature = feature.float()\n",
    "        feature = feature.view(1,6)\n",
    "        return feature\n",
    "    feature  = get_shadow(x,0)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature,weights):\n",
    "    y=-1\n",
    "    #[feature 1], added dimension to represent 'b' parameter\n",
    "    feature = torch.cat((feature,torch.tensor(1.0).view(1,1)),1)\n",
    "    feature2=feature.mul(feature)\n",
    "    y = feature.mm(weights[:,0:1])+feature2.mm(weights[:,1:2])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(image_data,image_label,weights,lr):\n",
    "    loss_value_before=100000000.\n",
    "    loss_value=1000000.\n",
    "    for epoch in range(0,3000):\n",
    "        loss_value_before=loss_value\n",
    "        loss_value=0\n",
    "        for i in range(0,10):\n",
    "\n",
    "            feature = get_feature(image_data[i])\n",
    "            y = model(feature,weights)\n",
    "            \n",
    "            #L2 loss\n",
    "            loss = 0.5*(y-image_label[i])*(y-image_label[i])\n",
    "\n",
    "            loss_value += loss.data.item()\n",
    "\n",
    "            # w  = w - (y-y1)*x*lr\n",
    "\n",
    "            loss.backward()\n",
    "            #weights.data.sub_(weights.grad.data*lr)\n",
    "            #weights.grad.data.zero_()\n",
    "            with torch.no_grad():\n",
    "                weights -= weights.grad*lr\n",
    "                weights.grad.zero_()\n",
    "            #loss.data=\n",
    "        if epoch%300 == 0:\n",
    "            print(\"epoch=%s,loss=%s/%s,weights=%s\"%(epoch,loss_value,loss_value_before,weights))\n",
    "        #epoch+=1\n",
    "        #loss_value=0\n",
    "        #:loss=0\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1, 0],\n",
      "        [0, 1, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0]])\n",
      "--------------------\n",
      "tensor([[0, 0, 1, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 0],\n",
      "        [0, 0, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0]])\n",
      "--------------------\n",
      "epoch=0,loss=3.928820914648576e+20/1000000.0,weights=tensor([[-4.1741e-01,  3.3697e-01],\n",
      "        [-3.0446e+09, -6.0821e+09],\n",
      "        [-3.1632e+09, -6.6751e+09],\n",
      "        [-3.1955e+09, -6.8365e+09],\n",
      "        [-7.2425e+09, -3.5432e+10],\n",
      "        [-7.6787e+03, -7.6799e+03],\n",
      "        [-1.5271e+09, -1.5271e+09]], requires_grad=True)\n",
      "epoch=300,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "epoch=600,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "epoch=900,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "epoch=1200,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "epoch=1500,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "epoch=1800,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "epoch=2100,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "epoch=2400,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "epoch=2700,loss=nan/nan,weights=tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], requires_grad=True)\n",
      "0 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 3., 2., 2., 3., 0.]])\n",
      "1 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 0., 2., 5., 1., 0.]])\n",
      "2 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 2., 3., 3., 2., 0.]])\n",
      "3 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 0., 3., 3., 2., 0.]])\n",
      "4 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 1., 2., 2., 5., 1.]])\n",
      "5 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 4., 3., 3., 1., 0.]])\n",
      "6 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 3., 3., 3., 1., 0.]])\n",
      "7 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 1., 1., 4., 2., 0.]])\n",
      "8 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 2., 3., 3., 2., 0.]])\n",
      "9 tensor([[nan]], grad_fn=<AddBackward0>) tensor([[0., 2., 2., 2., 5., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights = torch.randn(7,2,requires_grad = True)\n",
    "image_label = labels\n",
    "image_data= generate_data()\n",
    "\n",
    "print(image_data[0])\n",
    "print(\"-\"*20)\n",
    "\n",
    "\n",
    "print(image_data[8])\n",
    "print(\"-\"*20)\n",
    "\n",
    "\n",
    "lr = -0.05\n",
    "\n",
    "weights=train_model(image_data,image_label,weights,lr)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    x=image_data[i]\n",
    "\n",
    "    feature=get_feature(x)\n",
    "\n",
    "    y = model(feature,weights)\n",
    "\n",
    "    print(i,y,feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
